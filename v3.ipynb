{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":39272,"databundleVersionId":4629629,"sourceType":"competition"},{"sourceId":4619805,"sourceType":"datasetVersion","datasetId":2688675},{"sourceId":4824226,"sourceType":"datasetVersion","datasetId":2794616}],"dockerImageVersionId":30356,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\n\nThe transformer is a general and powerful neural network architecture, able to tackle many real-world problems. Vision transformer (ViT) is a transformer for computer vision tasks. In this notebook, Vision Transformer (ViT) is implemented from scratch using PyTorch for image classification. Later, we will train the model on a subset of RSNA breast cancer detection dataset.","metadata":{}},{"cell_type":"markdown","source":"# 1. About the Architecture\nTransformers found their initial applications in natural language processing (NLP) tasks. To use this NLP model for computer vision tasks, we have to divide our input image into patches. After flattening the patches, we can treat each flattened patches as single word. We add positional embeddings to the linear projection of flattened patches. An extra token is added at the beginning for classification tasks. In BERT model, this token is called [CLS] token.\n\nSo if our input image size is (512, 512), after dividing the image into patches of size (16, 16), we get 1024 (32 times 32) patches. After flattening the patches and projecting the flattened patches, we have 1024 tokens. After adding positional embeddings and concatenating classification token at the beginning, we have 1025 tokens.\n\nWe then feed our tokens into the transformer encoder. Transformer encoder is made up of self attention and feedforward network. The [original paper](https://paperswithcode.com/paper/attention-is-all-you-need) on attention is an excellent read if you want to understand the whole attention mechanism. PyTorch have `torch.nn.MultiHeadAttention` for anyone who one to use attention mechanism for their next project. This [video](https://www.youtube.com/watch?v=_UVfwBqcnbM) by AssemblyAI is explains the transformer architecture beautifully.\n\nThe number of tokens in the output of the transformer encoder is equal to number of input tokens. We take the first token from the output (corresponds to the classification token) and feed the token in a multilayer perceptron head for classification.\n\nFor more details, you can go through [original paper](https://paperswithcode.com/method/vision-transformer) on Vision Transformer.\n\n![Vision Transformer](https://production-media.paperswithcode.com/methods/Screen_Shot_2021-01-26_at_9.43.31_PM_uI4jjMq.png)","metadata":{}},{"cell_type":"markdown","source":"# 2. About the Dataset\nThe dataset was contributed by mammography screening programs in Australia and the U.S. It includes detailed labels, with radiologists’ evaluations and follow-up pathology results for suspected malignancies. \n\nThe dataset is stored in dicom formats. Converting dicom data to png/jpg just by rescaling it will harm the quality of the data. [This notebook](https://www.kaggle.com/code/raddar/convert-dicom-to-np-array-the-correct-way/notebook) is an awesome resource for anyone working with dicom files for X-Ray.","metadata":{}},{"cell_type":"markdown","source":"# 3. Implementation","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Utility functions\nWe write some utility functions beforehand.","metadata":{}},{"cell_type":"code","source":"import os\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pydicom\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Accuracy, Loss, RunningAverage\nfrom ignite.contrib.handlers import ProgressBar\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import models, transforms","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:21:14.054927Z","iopub.execute_input":"2023-11-23T12:21:14.055253Z","iopub.status.idle":"2023-11-23T12:21:20.303732Z","shell.execute_reply.started":"2023-11-23T12:21:14.055178Z","shell.execute_reply":"2023-11-23T12:21:20.302607Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def read_xray(file_path, img_size=None):\n    \"\"\"\n    Read the dicom data and get the image\n    Args:\n        file_path: The path of the dicom file\n        img_size: Size of the output image\n    \"\"\"\n\n    dicom = pydicom.read_file(file_path)\n    img = dicom.pixel_array\n\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        img = np.max(img) - img\n\n    if img_size:\n        img = cv2.resize(img, img_size)\n\n    # Add channel dim at First\n    img = img[np.newaxis]\n\n    # Converting img to float32\n    img = img / np.max(img)\n    img = img.astype(\"float32\")\n\n    return img","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:21:20.305687Z","iopub.execute_input":"2023-11-23T12:21:20.306147Z","iopub.status.idle":"2023-11-23T12:21:20.314168Z","shell.execute_reply.started":"2023-11-23T12:21:20.306117Z","shell.execute_reply":"2023-11-23T12:21:20.313053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def patchify(batch, patch_size):\n    \"\"\"\n    Patchify the batch of images\n        \n    Shape:\n        batch: (b, h, w, c)\n        output: (b, nh, nw, ph, pw, c)\n    \"\"\"\n    b, c, h, w = batch.shape\n    ph, pw = patch_size\n    nh, nw = h // ph, w // pw\n\n    batch_patches = torch.reshape(batch, (b, c, nh, ph, nw, pw))\n    batch_patches = torch.permute(batch_patches, (0, 1, 2, 4, 3, 5))\n\n    return batch_patches","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:21:20.315838Z","iopub.execute_input":"2023-11-23T12:21:20.316434Z","iopub.status.idle":"2023-11-23T12:21:20.326114Z","shell.execute_reply.started":"2023-11-23T12:21:20.316402Z","shell.execute_reply":"2023-11-23T12:21:20.325121Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We test our `patchify` function on a single image.","metadata":{}},{"cell_type":"code","source":"FILE_PATH = ('/kaggle/input/rsna-breast-cancer-detection/'\n             'train_images/10006/1459541791.dcm')\n\nimg = read_xray(FILE_PATH, img_size=(512, 512))\n\nbatch = torch.tensor(img[None])\npatch_size = (16, 16)\nbatch_patches = patchify(batch, patch_size)\n\npatches = batch_patches[0]\nc, nh, nw, ph, pw = patches.shape\n\nplt.figure(figsize=(5, 5))\nplt.imshow(img[0], cmap=\"gray\")\nplt.axis(\"off\")\n\nplt.figure(figsize=(5, 5))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:26.797034Z","iopub.execute_input":"2023-11-23T12:22:26.797475Z","iopub.status.idle":"2023-11-23T12:22:28.337718Z","shell.execute_reply.started":"2023-11-23T12:22:26.797443Z","shell.execute_reply":"2023-11-23T12:22:28.336627Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<Figure size 360x360 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 360x360 with 0 Axes>"},"metadata":{}}]},{"cell_type":"code","source":"def get_mlp(in_features, hidden_units, out_features):\n    \"\"\"\n    Returns a MLP head\n    \"\"\"\n    dims = [in_features] + hidden_units + [out_features]\n    layers = []\n    for dim1, dim2 in zip(dims[:-2], dims[1:-1]):\n        layers.append(nn.Linear(dim1, dim2))\n        layers.append(nn.ReLU())\n    layers.append(nn.Linear(dims[-2], dims[-1]))\n    return nn.Sequential(*layers)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:31.327491Z","iopub.execute_input":"2023-11-23T12:22:31.327949Z","iopub.status.idle":"2023-11-23T12:22:31.335372Z","shell.execute_reply.started":"2023-11-23T12:22:31.327906Z","shell.execute_reply":"2023-11-23T12:22:31.334292Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Image to Sequence Block\nThis Block takes a batch of image as input and returns a batch of sequences. Later on we feed this sequences into the transformer encoder.","metadata":{}},{"cell_type":"code","source":"class Img2Seq(nn.Module):\n    \"\"\"\n    This layers takes a batch of images as input and\n    returns a batch of sequences\n    \n    Shape:\n        input: (b, h, w, c)\n        output: (b, s, d)\n    \"\"\"\n    def __init__(self, img_size, patch_size, n_channels, d_model):\n        super().__init__()\n        self.patch_size = patch_size\n        self.img_size = img_size\n\n        nh, nw = img_size[0] // patch_size[0], img_size[1] // patch_size[1]\n        n_tokens = nh * nw\n\n        token_dim = patch_size[0] * patch_size[1] * n_channels\n        self.linear = nn.Linear(token_dim, d_model)\n        self.cls_token = nn.Parameter(torch.randn(1, 1, d_model))\n        self.pos_emb = nn.Parameter(torch.randn(n_tokens, d_model))\n\n    def __call__(self, batch):\n        batch = patchify(batch, self.patch_size)\n\n        b, c, nh, nw, ph, pw = batch.shape\n\n        # Flattening the patches\n        batch = torch.permute(batch, [0, 2, 3, 4, 5, 1])\n        batch = torch.reshape(batch, [b, nh * nw, ph * pw * c])\n\n        batch = self.linear(batch)\n        cls = self.cls_token.expand([b, -1, -1])\n        emb = batch + self.pos_emb\n\n        return torch.cat([cls, emb], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:34.036305Z","iopub.execute_input":"2023-11-23T12:22:34.036695Z","iopub.status.idle":"2023-11-23T12:22:34.048872Z","shell.execute_reply.started":"2023-11-23T12:22:34.036662Z","shell.execute_reply":"2023-11-23T12:22:34.047768Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Visual Transformer Module\nThis modules wraps up everything. We can divide this module into 3 parts: \n* An image to sequence encoder\n* Transformer encoder\n* Multilayer perceptron head classification\n\nWe use `torch.nn.TransformerEncoder` and `torch.nn.TransformerEncoderLayer` to implement our transformer encoder. I highly recommend to read the official documentation to learn more about the layers.","metadata":{}},{"cell_type":"code","source":"class ViT(nn.Module):\n    def __init__(\n        self,\n        img_size,\n        patch_size,\n        n_channels,\n        d_model,\n        nhead,\n        dim_feedforward,\n        blocks,\n        mlp_head_units,\n        n_classes,\n    ):\n        super().__init__()\n        \"\"\"\n        Args:\n            img_size: Size of the image\n            patch_size: Size of the patch\n            n_channels: Number of image channels\n            d_model: The number of features in the transformer encoder\n            nhead: The number of heads in the multiheadattention models\n            dim_feedforward: The dimension of the feedforward network model in the encoder\n            blocks: The number of sub-encoder-layers in the encoder\n            mlp_head_units: The hidden units of mlp_head\n            n_classes: The number of output classes\n        \"\"\"\n        self.img2seq = Img2Seq(img_size, patch_size, n_channels, d_model)\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model, nhead, dim_feedforward, activation=\"gelu\", batch_first=True\n        )\n        self.transformer_encoder = nn.TransformerEncoder(\n            encoder_layer, blocks\n        )\n        self.mlp = get_mlp(d_model, mlp_head_units, n_classes)\n        \n        self.output = nn.Sigmoid() if n_classes == 1 else nn.Softmax()\n\n    def __call__(self, batch):\n\n        batch = self.img2seq(batch)\n        batch = self.transformer_encoder(batch)\n        batch = batch[:, 0, :]\n        batch = self.mlp(batch)\n        output = self.output(batch)\n        return output","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:37.537785Z","iopub.execute_input":"2023-11-23T12:22:37.538161Z","iopub.status.idle":"2023-11-23T12:22:37.548334Z","shell.execute_reply.started":"2023-11-23T12:22:37.538132Z","shell.execute_reply":"2023-11-23T12:22:37.547320Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# 4. Training\n\nHere, we design a simple training to loop to train or `ViT` model on a subset of dataset. We use an already cropped dataset.","metadata":{}},{"cell_type":"markdown","source":"## 4.1 Model Hyperparameters","metadata":{}},{"cell_type":"code","source":"img_size = (512, 512)\npatch_size = (16, 16)\nn_channels = 1\nd_model = 1024\nnhead = 4\ndim_feedforward = 2048\nblocks = 8\nmlp_head_units = [1024, 512]\nn_classes = 1\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:41.057694Z","iopub.execute_input":"2023-11-23T12:22:41.058071Z","iopub.status.idle":"2023-11-23T12:22:41.165599Z","shell.execute_reply.started":"2023-11-23T12:22:41.058040Z","shell.execute_reply":"2023-11-23T12:22:41.164498Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## 4.2. Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class RSNADataset(Dataset):\n    \n    def __init__(self, df, img_path):\n        self.df = df\n        self.img_path = img_path\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        patient_id, image_id, cancer = self.df.iloc[idx][['patient_id', 'image_id', 'cancer']]\n        file = os.path.join(self.img_path, f'{patient_id}_{image_id}.png')\n        file = cv2.imread(file, cv2.COLOR_BGR2GRAY)\n        clahe = cv2.createCLAHE(clipLimit = 15, tileGridSize=[8, 8])\n        file = clahe.apply(file)\n        file = file / file.max()\n        X = torch.tensor(file[np.newaxis].astype('float32')).to(device)\n        y = torch.tensor([cancer]).float().to(device)\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:42.557436Z","iopub.execute_input":"2023-11-23T12:22:42.558124Z","iopub.status.idle":"2023-11-23T12:22:42.567836Z","shell.execute_reply.started":"2023-11-23T12:22:42.558086Z","shell.execute_reply":"2023-11-23T12:22:42.566662Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/train.csv')\ncounts = df['cancer'].value_counts()\ndf['weights'] = df['cancer'].apply(lambda x: 1/counts[x])\n\ntrain_df, val_df = train_test_split(df, test_size=0.25, stratify=df['cancer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:43.331251Z","iopub.execute_input":"2023-11-23T12:22:43.332139Z","iopub.status.idle":"2023-11-23T12:22:43.869949Z","shell.execute_reply.started":"2023-11-23T12:22:43.332100Z","shell.execute_reply":"2023-11-23T12:22:43.869143Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"img_path = '/kaggle/input/rsna-breast-cancer-512-pngs'\ntrain_samples = 1000\nval_samples = 500\n\ntrain_ds = RSNADataset(train_df, img_path)\nval_ds = RSNADataset(val_df, img_path)\n\ntrain_sampler = WeightedRandomSampler(train_df['weights'].values, train_samples)\ntrain_loader = DataLoader(train_ds, batch_size=8, sampler=train_sampler)\n\nval_sampler = WeightedRandomSampler(val_df['weights'].values, val_samples)\nval_loader = DataLoader(val_ds, batch_size=32, sampler=val_sampler)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:22:46.091495Z","iopub.execute_input":"2023-11-23T12:22:46.091886Z","iopub.status.idle":"2023-11-23T12:22:46.099568Z","shell.execute_reply.started":"2023-11-23T12:22:46.091854Z","shell.execute_reply":"2023-11-23T12:22:46.098640Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 4.3 Training and Validation","metadata":{}},{"cell_type":"code","source":"model = ViT(\n    img_size = (512, 512),\n    patch_size = (16, 16),\n    n_channels = 1,\n    d_model = 1024,\n    nhead = 4,\n    dim_feedforward = 1024,\n    blocks = 8,\n    mlp_head_units = [512, 512],\n    n_classes = 1,\n).to(device)\n\n# 优化器和模型实例化（确保模型在设备上）\noptimizer = torch.optim.Adam(model.parameters())\nmodel.to(device)\n\n# 损失函数\ncriterion = nn.BCELoss() \n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device=device)\nfrom ignite.metrics import ThresholdedBinaryAccuracy\n\n# 验证评估器配置\nval_metrics = {\n    \"accuracy\": ThresholdedBinaryAccuracy(threshold=0.5),  # 你可以根据需要调整阈值\n    \"bce\": Loss(criterion)\n    # 其他度量指标可以继续添加，根据需要调整\n}\n\n\nevaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T13:20:18.425378Z","iopub.execute_input":"2023-11-23T13:20:18.425823Z","iopub.status.idle":"2023-11-23T13:20:18.604922Z","shell.execute_reply.started":"2023-11-23T13:20:18.425787Z","shell.execute_reply":"2023-11-23T13:20:18.603621Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2361081985.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_supervised_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mThresholdedBinaryAccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# 验证评估器配置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'ThresholdedBinaryAccuracy' from 'ignite.metrics' (/opt/conda/lib/python3.7/site-packages/ignite/metrics/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'ThresholdedBinaryAccuracy' from 'ignite.metrics' (/opt/conda/lib/python3.7/site-packages/ignite/metrics/__init__.py)","output_type":"error"}]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\nfrom ignite.metrics import Loss, Accuracy\nfrom ignite.contrib.handlers import ProgressBar\n\n# Assuming you have defined your model, optimizer, criterion, train_loader, val_loader, and other necessary components\n\n# Hyperparameters\nmax_epochs = 10\nlog_interval = 10\nbest_loss = float('inf')\n\nRunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Your model, optimizer, criterion, train_loader, val_loader definitions go here...\n\n# Define the trainer and evaluator\ntrainer = create_supervised_trainer(model, optimizer, criterion, device=device)\nevaluator = create_supervised_evaluator(model, metrics={'bce': Loss(torch.nn.BCELoss()), 'accuracy': Accuracy()}, device=device)\n\n# Add ProgressBar\npbar = ProgressBar()\npbar.attach(trainer, ['loss'])\n\n# Lists to store training and validation metrics\ntrain_losses = []\nval_losses = []\nval_accuracies = []\nepochs = []\n\n# Define training and validation logging functions\ndef log_training_results(engine):\n    loss = engine.state.output\n    train_losses.append(loss)\n    print(f\"Training Results - Epoch: {engine.state.epoch} Avg loss: {loss:.2f}\")\n\ndef log_validation_results(engine):\n    global best_loss\n    evaluator.run(val_loader)\n    \n    # Retrieve metrics\n    loss = evaluator.state.metrics['bce']\n    accuracy = evaluator.state.metrics['accuracy']\n    \n    # Save losses and accuracies for plotting\n    val_losses.append(loss)\n    val_accuracies.append(accuracy)\n\n    if loss < best_loss:\n        best_loss = loss\n        torch.save(model.state_dict(), 'best_model_vit.pt')\n\n    print(f\"Validation Results - Epoch: {engine.state.epoch} Avg loss: {loss:.2f} Accuracy: {accuracy:.2%}\")\n\n# Attach events to the trainer\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, log_training_results)\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, log_validation_results)\n\n# Training loop\noutput_state =trainer.run(train_loader, max_epochs=max_epochs)\n\n# Plot the results after training completes\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\n\n# Plot Loss\nplt.subplot(1, 2, 1)\nplt.plot(range(1, max_epochs + 1), train_losses, label='Training Loss', marker='o')\nplt.plot(range(1, max_epochs + 1), val_losses, label='Validation Loss', marker='o')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot Accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(1, max_epochs + 1), val_accuracies, label='Validation Accuracy', marker='o', color='orange')\nplt.title('Validation Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T13:16:16.909986Z","iopub.execute_input":"2023-11-23T13:16:16.910376Z","iopub.status.idle":"2023-11-23T13:18:49.434208Z","shell.execute_reply.started":"2023-11-23T13:16:16.910343Z","shell.execute_reply":"2023-11-23T13:18:49.432299Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Training Results - Epoch: 1 Avg loss: 0.69\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2978471414.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0moutput_state\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Plot the results after training completes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterrupt_resume_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                     \u001b[0mhandlers_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m                     \u001b[0mepoch_time_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mhandlers_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     \u001b[0;31m# update time wrt handlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/2978471414.py\u001b[0m in \u001b[0;36mlog_validation_results\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_validation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Retrieve metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterrupt_resume_enabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    957\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                     \u001b[0mepoch_time_taken\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset_as_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                     \u001b[0;31m# time is available for handlers but must be updated after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Current run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_terminate_or_interrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36miteration_completed\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_o1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_o2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36m_check_type\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mupdate_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_binary_multilabel_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multilabel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36m_check_binary_multilabel_cases\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For binary cases, y_pred must be comprised of 0's and 1's.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: For binary cases, y_pred must be comprised of 0's and 1's."],"ename":"ValueError","evalue":"For binary cases, y_pred must be comprised of 0's and 1's.","output_type":"error"}]},{"cell_type":"code","source":"log_interval = 10\nmax_epochs = 5\nbest_loss = float('inf')\n\nRunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n\npbar = ProgressBar()\npbar.attach(trainer, ['loss'])\n    \n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_validation_results(trainer):\n    global best_loss\n    evaluator.run(val_loader)\n    loss = evaluator.state.metrics['bce']\n    if loss < best_loss:\n        best_loss = loss\n        torch.save(model.state_dict(), 'best_model_vit.pt')\n    print(f\"Validation Results - Epoch: {trainer.state.epoch} Avg loss: {loss:.2f}\")\n    \noutput_state = trainer.run(train_loader, max_epochs=max_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:59:12.057539Z","iopub.execute_input":"2023-11-23T12:59:12.058333Z","iopub.status.idle":"2023-11-23T12:59:12.067073Z","shell.execute_reply.started":"2023-11-23T12:59:12.058292Z","shell.execute_reply":"2023-11-23T12:59:12.066114Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 Comparison with resnet50","metadata":{}},{"cell_type":"code","source":"resnet = models.resnet50(pretrained=True)\nin_features = resnet.fc.in_features\nresnet.fc = nn.Linear(in_features, 1)\n\nresnet_transforms= transforms.Compose([\n    transforms.Resize((228, 228)),\n    transforms.Lambda(lambda x: x.repeat([1, 3, 1, 1]))\n])\n\nclass MyResNet(nn.Module):\n    \n    def __init__(self, transforms, model):\n        super().__init__()\n        self.transforms = transforms\n        self.model = model\n        self.output = nn.Sigmoid()\n        \n    def forward(self, batch):\n        batch = self.transforms(batch)\n        batch = self.model(batch)\n        return self.output(batch)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:59:18.837932Z","iopub.execute_input":"2023-11-23T12:59:18.838875Z","iopub.status.idle":"2023-11-23T12:59:20.261261Z","shell.execute_reply.started":"2023-11-23T12:59:18.838836Z","shell.execute_reply":"2023-11-23T12:59:20.260066Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91066a8a02b146cdb01eba61f7cadf5e"}},"metadata":{}}]},{"cell_type":"code","source":"model = MyResNet(resnet_transforms, resnet).to(device)\n\noptimizer = Adam(model.parameters())\ncriterion = nn.BCELoss()\n\ntrainer = create_supervised_trainer(model, optimizer, criterion, device=device)\nval_metrics = {\n    \"bce\": Loss(criterion)\n}\nevaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:59:20.263466Z","iopub.execute_input":"2023-11-23T12:59:20.264299Z","iopub.status.idle":"2023-11-23T12:59:20.308141Z","shell.execute_reply.started":"2023-11-23T12:59:20.264249Z","shell.execute_reply":"2023-11-23T12:59:20.307165Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n\npbar = ProgressBar()\npbar.attach(trainer, ['loss'])\n    \n@trainer.on(Events.EPOCH_COMPLETED)\ndef log_validation_results(trainer):\n    global best_loss\n    evaluator.run(val_loader)\n    loss = evaluator.state.metrics['bce']\n    if loss < best_loss:\n        best_loss = loss\n        torch.save(model.state_dict(), 'best_model_resnet.pt')\n    print(f\"Validation Results - Epoch: {trainer.state.epoch} Avg loss: {loss:.2f}\")\n    \noutput_state = trainer.run(train_loader, max_epochs=max_epochs)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T12:59:20.309689Z","iopub.execute_input":"2023-11-23T12:59:20.310337Z","iopub.status.idle":"2023-11-23T13:02:27.550111Z","shell.execute_reply.started":"2023-11-23T12:59:20.310297Z","shell.execute_reply":"2023-11-23T13:02:27.548803Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Results - Epoch: 1 Avg loss: 1.53\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Results - Epoch: 2 Avg loss: 0.69\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Results - Epoch: 3 Avg loss: 0.69\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Results - Epoch: 4 Avg loss: 0.70\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[1/125]   1%|           [00:00<?]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Validation Results - Epoch: 5 Avg loss: 0.71\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Next Step\n\n* You can checkout [huggingface](httfc://huggingface.co/docs/transformers/model_doc/vit) for pretrained vision transformers.\n* For implementation of ViT in tensorflow and keras, checkout this [tutorial](https://keras.io/examples/vision/image_classification_with_vision_transformer/).\n\nUpvote the notebook if you like it. Feel free to give feedback in the comment section down below!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}